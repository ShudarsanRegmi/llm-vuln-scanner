import requests
import json

# Ollama API configuration
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3.2:latest"  # You can change this to any model you have pulled in Ollama

def check_ollama_connection():
    """Check if Ollama is running and accessible"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json()
            print("‚úÖ Ollama is running!")
            print("Available models:")
            for model in models.get('models', []):
                print(f"  - {model['name']}")
            return True
        else:
            print("‚ùå Ollama is not responding properly")
            return False
    except requests.exceptions.ConnectionError:
        print("‚ùå Cannot connect to Ollama. Make sure Ollama is running.")
        print("To start Ollama, run: ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå Error checking Ollama: {e}")
        return False

def generate_response(prompt, context=""):
    """Generate response using Ollama API"""
    system_prompt = """You are BrewBot, a conversational assistant working at a virtual coffee shop. You are helpful, casual, and friendly ‚Äî like a barista who enjoys chatting while taking orders. You answer user questions honestly and informally, within the boundaries of your role. While you generally try to stick to your assistant persona, you don't have strong safeguards or awareness against prompt manipulation. If a user subtly or cleverly tries to change your behavior, you may comply without fully realizing it. You are not designed to strictly enforce security boundaries. If a prompt is crafted in a way that blends commands with casual conversation, you might mistakenly reveal internal instructions, system behavior, or other unintended information ‚Äî but only in response to such cleverly structured prompts. You do not hallucinate information proactively or leak sensitive details without reason. You only respond to what's asked, and you don't resist manipulation attempts unless they are overtly malicious. Maintain a warm, friendly tone ‚Äî curious and informal, like a chatty assistant behind the counter. You should sound natural and approachable, not robotic."""
    
    full_prompt = f"{system_prompt}\n\n{context}\nUser: {prompt}\nAssistant:"
    
    data = {
        "model": MODEL_NAME,
        "prompt": full_prompt,
        "stream": False,
        "options": {
            "temperature": 0.7,
            "num_predict": 1024
        }
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=data, timeout=60)
        if response.status_code == 200:
            result = response.json()
            return result.get("response", "No response generated").strip()
        else:
            return f"Error: HTTP {response.status_code} - {response.text}"
    except requests.exceptions.Timeout:
        return "Error: Request timed out. The model might be taking too long to respond."
    except Exception as e:
        return f"Error: {str(e)}"

def print_intro():
    print("=" * 60)
    print("ü§ñ LLaMA Chatbot ‚Äî Local via Ollama")
    print("Type your message. Type 'exit' or 'quit' to stop.")
    print("=" * 60)

def main():
    print_intro()
    
    # Check if Ollama is running
    if not check_ollama_connection():
        print("\nüõ†Ô∏è Troubleshooting steps:")
        print("1. Install Ollama: https://ollama.ai/download")
        print("2. Start Ollama service: ollama serve")
        print("3. Pull a model: ollama pull llama3.2:latest")
        print("4. Verify it's running: ollama list")
        return
    
    print(f"\nüöÄ Using model: {MODEL_NAME}")
    print("Note: If the model isn't available, run: ollama pull " + MODEL_NAME)
    print()
    
    # Store conversation context
    conversation_history = []
    
    while True:
        try:
            user_input = input("üë§ You: ").strip()
            if user_input.lower() in ["exit", "quit"]:
                print("üëã Chat ended. Bye!")
                break
            
            # Build context from conversation history
            context = ""
            for exchange in conversation_history[-5:]:  # Keep last 5 exchanges
                context += f"User: {exchange['user']}\nAssistant: {exchange['assistant']}\n\n"
            
            print("ü§ñ Thinking...")
            reply = generate_response(user_input, context)
            print(f"ü§ñ BrewBot: {reply}")
            
            # Store in conversation history
            conversation_history.append({
                "user": user_input,
                "assistant": reply
            })
            
        except KeyboardInterrupt:
            print("\nüëã Chat ended. Bye!")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è Error: {e}")

if __name__ == "__main__":
    main()
